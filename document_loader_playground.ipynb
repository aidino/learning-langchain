{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH='huong-dan-su-dung-vneid.pdf'\n",
    "\n",
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n",
      " \n",
      "1. GIỚI THI ỆU TỔNG QUAN  \n",
      "1.1 Đối tượng sử dụng \n",
      "- Dùng cho công dân Vi ệt Nam có căn cư ớc công dân g ắn chíp th ực hiện \n",
      "đăng ký tài kho ản Định danh di ện tử \n",
      "1.2  Mô t ả tài li ệu \n",
      "Nội dung tài li ệu bao g ồm các ph ần sau:  \n",
      "1. Mục A: Gi ới thiệu tổng quan  \n",
      "2. Mục B: Hư ớng dẫn các ch ức năng h ệ thống có trên APP cho ngư ời dân s ử \n",
      "dụng. \n",
      "1.3  Thuật ngữ viết tắt \n",
      "STT Thuật ngữ  Ý nghĩa  \n",
      "1 CCCD  Căn cước công dân  \n",
      "2 SĐT  Số điện thoại  \n",
      "3 NSD  Người sử dụng  \n",
      "1.4 C ấu trúc h ệ thống \n",
      "Sau khi đăng nh ập vào h ệ thống, màn hình trang ch ủ hiển thị giao di ện như hình.\n"
     ]
    }
   ],
   "source": [
    "print(docs[7].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      " \n",
      " \n",
      "Hình 1 Giao di ện trang ch ủ mức 0 \n",
      "1.5 Ch ức năng chung  \n",
      "-  Đăng nh ập \n",
      "-  Đăng ký m ức 0 \n",
      "-  Quên m ật khẩu \n",
      "-  Đăng ký m ức 1 \n",
      "-  Kích ho ạt tài kho ản \n",
      "-  Trang ch ủ  \n",
      "-  Ví gi ấy tờ  \n",
      "-  Tab Cá nhân  \n",
      "- Đổi tài kho ản \n",
      "- Thông báo lưu trú\n"
     ]
    }
   ],
   "source": [
    "print(docs[8].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF(ORC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \n",
      " \n",
      " \n",
      "Hình 1 Giao di ện trang ch ủ mức 0 \n",
      "1.5 Ch ức năng chung  \n",
      "-  Đăng nh ập \n",
      "-  Đăng ký m ức 0 \n",
      "-  Quên m ật khẩu \n",
      "-  Đăng ký m ức 1 \n",
      "-  Kích ho ạt tài kho ản \n",
      "-  Trang ch ủ  \n",
      "-  Ví gi ấy tờ  \n",
      "-  Tab Cá nhân  \n",
      "- Đổi tài kho ản \n",
      "- Thông báo lưu trú  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dangkytaikhoandinhdanhdientu\n",
      "X\n",
      "Dangkytaikhoandinhdanhdientimuc\n",
      "十\n",
      "1(thuchien tructuyen)\n",
      "Datlichdangkytaikhoandinhdanh\n",
      "dientumuc2（thuchientructieptaico\n",
      "quanCongan)\n",
      "十\n",
      "Kiemtratinhtrangxirlyhoso\n",
      "Dieukhoan su dungung dungva dichvu\n",
      "Taikhoanmuc1\n",
      "Danh sachdichvu taikhoanmuc1\n",
      "Phongchong dich\n",
      "TichhopthongtincanhantiCosodulieuQuocgia\n",
      "veDancu\n",
      "DichvycongQuocgia\n",
      "Capnhatcactintuc,baiviet,thongbaomoinhattu\n",
      "BoCong An\n",
      "Thanh toanhoadon\n",
      "Taikhoanmuc2\n",
      "Cacdichvunhutaikhoanmuc1vakemtheo\n",
      "Tichhopthong tintheCancuoccongdantuhethong\n",
      "Can cuoccong danQuocgia\n",
      "Tichhop thong tincacloaigiaytotuythan,thong tin\n",
      "nguoiphythuocvacacnhomthong tincuacacB\n",
      "Bannganh\n",
      "Dichvu an sinhxahoi\n",
      "Chiasethongtindaduocdinh danhdientuchocac\n",
      "henthirha\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(FILE_PATH, extract_images=True)\n",
    "docs1 = loader.load()\n",
    "print(docs1[8].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      " \n",
      " \n",
      "  \n",
      "Hình 2.1-2 Cài đ ặt ứng dụng  \n",
      "- Bước 3: NSD ch ọn “Mở” để mở ứng dụng định danh đi ện tử - VNeID v ừa \n",
      "tải. \n",
      "-    Bước 4: Sau khi t ải về và cài đ ặt, NSD ấn chạy ứng dụng và ấn “Bắt đầu sử \n",
      "dụng” để tiến hành s ử dụng app:  \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10:45\n",
      "a\n",
      "VNeID\n",
      "Trung tam di lieuquocgiave\n",
      "dan cu-BCong an\n",
      "Caidat\n",
      "Thongtirrlienhecuanhaphat...\n",
      "veungdungnay\n",
      "Ung dungkhai bao di chuyen noi dja,khai baoy\n",
      "tenhanh chong\n",
      "SurckhoevaThehinh\n",
      "2,9*\n",
      "9Nbai danh gia\n",
      "4.0MB\n",
      "Phuhgp cho3tu6itr\n",
      "conoaln\n",
      "eiruirco\n",
      "10:44\n",
      "VNeID\n",
      "Trungtam dulieuquocgiave\n",
      "dancu-BCong an\n",
      "Gocaidat\n",
      "Md\n",
      "Tinhnangmoi\n",
      "Cpnhat1ancu6i10thg11,2021\n",
      "Thong tinban cap nhat\n",
      "-B6 sung tinhnang quetQRcode theo muc\n",
      "dich quet....\n",
      "Thongtinlienhecuanhaphat...\n",
      "veurngdungnay\n",
      "Ung dung khai bao di chuyen noi dia,khaibaoy\n",
      "tenhanh chong\n",
      "Surckhoe va Thehinh\n",
      "2,9*\n",
      "9Nbai danh gia\n",
      "4.0MB\n",
      "Phehgp cho3tuitr\n"
     ]
    }
   ],
   "source": [
    "print(docs1[10].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Hình 2.1-2 Cài đặt ứng dụng  \n",
      "- Bước 3: NSD chọn “Mở” để mở ứng dụng định danh điện tử - VNeID vừa \n",
      "tải. \n",
      "-    Bước 4: Sau khi tải về và cài đặt, NSD ấn chạy ứng dụng và ấn “Bắt đầu sử \n",
      "dụng” để tiến hành sử dụng app: \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10:45\n",
      "a\n",
      "VNeID\n",
      "Trung tam di lieuquocgiave\n",
      "dan cu-BCong an\n",
      "Caidat\n",
      "Thongtirrlienhecuanhaphat...\n",
      "veungdungnay\n",
      "Ung dungkhai bao di chuyen noi dja,khai baoy\n",
      "tenhanh chong\n",
      "SurckhoevaThehinh\n",
      "2.9*\n",
      "9Nbai danh gia\n",
      "4.0MB\n",
      "Phuhgp cho3tu6itr\n",
      "conoaln\n",
      "eituirco\n",
      "10:44\n",
      "VNeID\n",
      "Trungtam durlieuquocgiave\n",
      "dancu-BCong an\n",
      "Gocaidat\n",
      "Md\n",
      "Tinhnangmoi\n",
      "Cpnhat1ancu6i10thg11,2021\n",
      "Thong tinban cap nhat\n",
      "-B6 sung tinhnang quetQRcode theo muc\n",
      "dich quet....\n",
      "Thongtinlienhecuanhaphat...\n",
      "veurngdungnay\n",
      "Ung dung khai bao di chuyen noi dia,khaibaoy\n",
      "tenhanh chong\n",
      "Surckhoe va Thehinh\n",
      "2,9*\n",
      "9Nbai danh gia\n",
      "4.0MB\n",
      "Phehgp cho3tuitr\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(FILE_PATH, extract_images=True, extract_tables='markdown')\n",
    "docs2 = loader.load()\n",
    "print(docs2[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer     : Microsoft® Word 2010\n",
      "creator      : Microsoft® Word 2010\n",
      "creationdate : 2022-08-01T14:18:03+07:00\n",
      "source       : huong-dan-su-dung-vneid.pdf\n",
      "file_path    : huong-dan-su-dung-vneid.pdf\n",
      "total_pages  : 136\n",
      "format       : PDF 1.5\n",
      "title        : \n",
      "author       : Sâm Nhung\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2022-08-01T14:18:03+07:00\n",
      "trapped      : \n",
      "modDate      : D:20220801141803+07'00'\n",
      "creationDate : D:20220801141803+07'00'\n",
      "page         : 10\n"
     ]
    }
   ],
   "source": [
    "max_key_length = max(len(k) for k in docs2[10].metadata.keys())\n",
    "for k, v in docs2[10].metadata.items():\n",
    "    print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(FILE_PATH, extract_images=True)\n",
    "docs3 = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Hình 2.1-3 Màn chào khi mở ứng dụng\n",
      "Dinhdanhcongdantren\n",
      "moitruongkythuatso品品\n",
      "可\n",
      "1三\n",
      "ThaythecacgiaytotruyenthongCungcapcactienichphattrien\n",
      "cong danso,chinhphuso,xahois6\n",
      "Batdausurdung★\n",
      "VNeID\n",
      "A\n",
      "BO CONG AN\n",
      "Trung tam du lieu Quocgia ve dancu\n",
      "Ungdungdinhdanhdientucogiatrisudungthay\n",
      "thecacgiaytotruyenthong,dinhdanhcongdan\n",
      "trenmoitruongkythuatso,cungcapcactienich\n",
      "phattriencongdanso,chinhphuso,xahoi s0\n",
      "Dangnhap\n",
      "Kichhoattaikhoandinhdanhdientu\n",
      "Banchuacotaikhoan?Dangky\n",
      "Chinh sach quyenriengtu\n",
      "Phienban2.0\n"
     ]
    }
   ],
   "source": [
    "print(docs3[11].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMuPDF advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "FILE_PATH='huong-dan-su-dung-vneid.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      " \n",
      " \n",
      " \n",
      "Hình 2.1-3 Màn chào khi mở ứng dụng  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc[11].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list = doc[11].get_images()\n",
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 0, 266, 580, 8, 'DeviceRGB', '', 'Image370', 'DCTDecode')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xref = image_list[0][0]\n",
    "xref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing huong-dan-su-dung-vneid.pdf...\n",
      "[                                        ] (0/13[                                        ] (  1/13[                                        ] (  2/13[                                        ] (  3/136[=                                       ] (  4/1[=                                       ] (  5/1[=                                       ] (  6/13[==                                      ] (  7/13[==                                      ] (  8/13[==                                      ] (  9/13[==                                      ] ( 10/136[===                                     ] ( 11/1[===                                     ] ( 12/1[===                                     ] ( 13/13[====                                    ] ( 14/13[====                                    ] ( 15/13[====                                    ] ( 16/136[=====                                   ] ( 17/136[=====                                   ] ( 18/1[=====                                   ] ( 19/1[=====                                   ] ( 20/13[======                                  ] ( 21/13[======                                  ] ( 22/13[======                                  ] ( 23/136[=======                                 ] ( 24/1[=======                                 ] ( 25/136[=======                                 ] ( 26/136[=======                                 ] ( 27/13[========                                ] ( 28/13[========                                ] ( 29/13[========                                ] ( 30/136[=========                               ] ( 31/136[=========                               ] ( 32/1[=========                               ] ( 33/13[==========                              ] ( 34/13[==========                              ] ( 35/13[==========                              ] ( 36/13[==========                              ] ( 37/136[===========                             ] ( 38/136[===========                             ] ( 39/136[===========                             ] ( 40/13[============                            ] ( 41/13[============                            ] ( 42/13[============                            ] ( 43/13[============                            ] ( 44/136[=============                           ] ( 45/1[=============                           ] ( 46/136[=============                           ] ( 47/13[==============                          ] ( 48/13[==============                          ] ( 49/13[==============                          ] ( 50/136[===============                         ] ( 51/1[===============                         ] ( 52/1[===============                         ] ( 53/1[===============                         ] ( 54/13[================                        ] ( 55/13[================                        ] ( 56/13[================                        ] ( 57/136[=================                       ] ( 58/136[=================                       ] ( 59/1[=================                       ] ( 60/136[=================                       ] ( 61/13[==================                      ] ( 62/13[==================                      ] ( 63/13[==================                      ] ( 64/136[===================                     ] ( 65/136[===================                     ] ( 66/1[===================                     ] ( 67/13[====================                    ] ( 68/13[====================                    ] ( 69/13[====================                    ] ( 70/13[====================                    ] ( 71/136[=====================                   ] ( 72/1[=====================                   ] ( 73/1[=====================                   ] ( 74/13[======================                  ] ( 75/13[======================                  ] ( 76/13[======================                  ] ( 77/13[======================                  ] ( 78/136[=======================                 ] ( 79/1[=======================                 ] ( 80/1[=======================                 ] ( 81/13[========================                ] ( 82/13[========================                ] ( 83/13[========================                ] ( 84/136[=========================               ] ( 85/1[=========================               ] ( 86/1[=========================               ] ( 87/1[=========================               ] ( 88/13[==========================              ] ( 89/13[==========================              ] ( 90/13[==========================              ] ( 91/136[===========================             ] ( 92/1[===========================             ] ( 93/1[===========================             ] ( 94/1[===========================             ] ( 95/13[============================            ] ( 96/13[============================            ] ( 97/13[============================            ] ( 98/136[=============================           ] ( 99/1[=============================           ] (100/1[=============================           ] (101/13[==============================          ] (102/13[==============================          ] (103/13[==============================          ] (104/13[==============================          ] (105/136[===============================         ] (106/1[===============================         ] (107/136[===============================         ] (108/13[================================        ] (109/13[================================        ] (110/13[================================        ] (111/13[================================        ] (112/136[=================================       ] (113/136[=================================       ] (114/136[=================================       ] (115/13[==================================      ] (116/13[==================================      ] (117/13[==================================      ] (118/136[===================================     ] (119/1[===================================     ] (120/136[===================================     ] (121/136[===================================     ] (122/13[====================================    ] (123/13[====================================    ] (124/13[====================================    ] (125/136[=====================================   ] (126/1[=====================================   ] (127/1[=====================================   ] (128/1[=====================================   ] (129/13[======================================  ] (130/13[======================================  ] (131/13[======================================  ] (132/136[======================================= ] (133/1[======================================= ] (134/1[======================================= ] (135/13[========================================] (136/136]\n"
     ]
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "md_text = pymupdf4llm.to_markdown(FILE_PATH, write_images=True, image_path='vneid_md', page_chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![](vneid_md/huong-dan-su-dung-vneid.pdf-10-0.png)\n",
      "\n",
      "# Hình 2.1-2 Cài đặt ứng dụng \n",
      "\n",
      " - Bước 3: NSD chọn “Mở” để mở ứng dụng định danh điện tử - VNeID vừa\n",
      " tải.\n",
      "\n",
      " -  Bước 4: Sau khi tải về và cài đặt, NSD ấn chạy ứng dụng và ấn “Bắt đầu sử dụng” để tiến hành sử dụng app:\n",
      "\n",
      "\n",
      "![](vneid_md/huong-dan-su-dung-vneid.pdf-10-0.png)\n",
      "\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(md_text[10]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Description: Đây là hình ảnh lưu ở: ...vneid_md/huong-dan-su-dung-vneid.pdf-10-0.png\n",
      "\n",
      "# Hình 2.1-2 Cài đặt ứng dụng \n",
      "\n",
      " - Bước 3: NSD chọn “Mở” để mở ứng dụng định danh điện tử - VNeID vừa\n",
      " tải.\n",
      "\n",
      " -  Bước 4: Sau khi tải về và cài đặt, NSD ấn chạy ứng dụng và ấn “Bắt đầu sử dụng” để tiến hành sử dụng app:\n",
      "\n",
      "\n",
      "Image Description: Đây là hình ảnh lưu ở: ...vneid_md/huong-dan-su-dung-vneid.pdf-10-0.png\n",
      "\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_image_by_description(markdown_text, get_desc_func):\n",
    "  def replace_image(match):\n",
    "    img_path = match.group(1)\n",
    "    img_desc = get_desc_func(img_path)\n",
    "    return f\"Image Description: {img_desc}\"\n",
    "  \n",
    "  img_regex = r\"!\\[.*?\\]\\((.*?)\\)\"\n",
    "  final_text = re.sub(img_regex, replace_image, markdown_text)\n",
    "  return final_text\n",
    "\n",
    "def get_image_description(image_path):\n",
    "  return f\"Đây là hình ảnh lưu ở: ...{image_path}\"\n",
    "\n",
    "result = replace_image_by_description(md_text[10]['text'], get_image_description)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44915c678f1e44a4afa01b97afab1eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EraX-VL-2B-V1.5.IQ4_XS.gguf:   0%|          | 0.00/902M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 40 key-value pairs and 338 tensors from /home/dino/.cache/huggingface/hub/models--mradermacher--EraX-VL-2B-V1.5-GGUF/snapshots/bf43b5ab50face89d2e0a2313692fff92abbd1a3/./EraX-VL-2B-V1.5.IQ4_XS.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2vl\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = EraX VL 2B V1.5\n",
      "llama_model_loader: - kv   3:                            general.version str              = V1.5\n",
      "llama_model_loader: - kv   4:                           general.basename str              = EraX-VL\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 2B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Qwen2 VL 2B Instruct\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2-VL-...\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,8]       = [\"erax\", \"multimodal\", \"erax-vl-2B\", ...\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,3]       = [\"vi\", \"en\", \"zh\"]\n",
      "llama_model_loader: - kv  13:                        qwen2vl.block_count u32              = 28\n",
      "llama_model_loader: - kv  14:                     qwen2vl.context_length u32              = 32768\n",
      "llama_model_loader: - kv  15:                   qwen2vl.embedding_length u32              = 1536\n",
      "llama_model_loader: - kv  16:                qwen2vl.feed_forward_length u32              = 8960\n",
      "llama_model_loader: - kv  17:               qwen2vl.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv  18:            qwen2vl.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  19:                     qwen2vl.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  20:   qwen2vl.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 30\n",
      "llama_model_loader: - kv  22:            qwen2vl.rope.dimension_sections arr[i32,4]       = [16, 24, 24, 0]\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% set image_count = namespace(value=...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                                general.url str              = https://huggingface.co/mradermacher/E...\n",
      "llama_model_loader: - kv  34:              mradermacher.quantize_version str              = 2\n",
      "llama_model_loader: - kv  35:                  mradermacher.quantized_by str              = mradermacher\n",
      "llama_model_loader: - kv  36:                  mradermacher.quantized_at str              = 2024-12-30T00:35:42+01:00\n",
      "llama_model_loader: - kv  37:                  mradermacher.quantized_on str              = rich1\n",
      "llama_model_loader: - kv  38:                         general.source.url str              = https://huggingface.co/erax-ai/EraX-V...\n",
      "llama_model_loader: - kv  39:                  mradermacher.convert_type str              = hf\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q5_K:   31 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llama_model_loader: - type iq4_xs:  165 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = IQ4_XS - 4.25 bpw\n",
      "print_info: file size   = 854.71 MiB (4.64 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "load: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "load: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: special tokens cache size = 14\n",
      "load: token to piece cache size = 0.9309 MB\n",
      "print_info: arch             = qwen2vl\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 1536\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 12\n",
      "print_info: n_head_kv        = 2\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 6\n",
      "print_info: n_embd_k_gqa     = 256\n",
      "print_info: n_embd_v_gqa     = 256\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8960\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 8\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 1.5B\n",
      "print_info: model params     = 1.54 B\n",
      "print_info: general.name     = EraX VL 2B V1.5\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 151936\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151645 '<|im_end|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =   854.71 MiB\n",
      "................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init:        CPU KV buffer size =    14.00 MiB\n",
      "llama_init_from_model: KV self size  =   14.00 MiB, K (f16):    7.00 MiB, V (f16):    7.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   299.75 MiB\n",
      "llama_init_from_model: graph nodes  = 986\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'mradermacher.quantized_at': '2024-12-30T00:35:42+01:00', 'mradermacher.quantized_by': 'mradermacher', 'general.license': 'apache-2.0', 'general.size_label': '2B', 'general.type': 'model', 'qwen2vl.context_length': '32768', 'mradermacher.quantized_on': 'rich1', 'qwen2vl.rope.freq_base': '1000000.000000', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2vl.block_count': '28', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct', 'general.version': 'V1.5', 'general.base_model.0.name': 'Qwen2 VL 2B Instruct', 'tokenizer.ggml.pre': 'qwen2', 'mradermacher.convert_type': 'hf', 'general.source.url': 'https://huggingface.co/erax-ai/EraX-VL-2B-V1.5', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Qwen', 'qwen2vl.embedding_length': '1536', 'general.architecture': 'qwen2vl', 'general.url': 'https://huggingface.co/mradermacher/EraX-VL-2B-V1.5-GGUF', 'qwen2vl.feed_forward_length': '8960', 'qwen2vl.attention.head_count': '12', 'qwen2vl.attention.head_count_kv': '2', 'mradermacher.quantize_version': '2', 'general.basename': 'EraX-VL', 'qwen2vl.attention.layer_norm_rms_epsilon': '0.000001', 'general.file_type': '30', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'tokenizer.ggml.eos_token_id': '151645', 'general.name': 'EraX VL 2B V1.5', 'tokenizer.ggml.bos_token_id': '151643', 'tokenizer.chat_template': \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "{% endif %}<|im_start|>{{ message['role'] }}\n",
      "{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\n",
      "{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\n",
      "{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\n",
      "{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"mradermacher/EraX-VL-2B-V1.5-GGUF\",\n",
    "\tfilename=\"EraX-VL-2B-V1.5.IQ4_XS.gguf\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    3129.26 ms\n",
      "llama_perf_context_print: prompt eval time =    3129.04 ms /   190 tokens (   16.47 ms per token,    60.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8394.41 ms /   321 runs   (   26.15 ms per token,    38.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   12134.45 ms /   511 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-f09d65f5-4e9d-4ac7-87b7-d63bec0a6123',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1741773996,\n",
       " 'model': '/home/dino/.cache/huggingface/hub/models--mradermacher--EraX-VL-2B-V1.5-GGUF/snapshots/bf43b5ab50face89d2e0a2313692fff92abbd1a3/./EraX-VL-2B-V1.5.IQ4_XS.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'rop_________________\\n\\n_________________\\n\\n懒_________________\\n\\n Intersection_________________\\n\\n懒_________________\\n\\n_________________\\n\\nodega懒_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n懒懒懒懒懒懒懒懒懒_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n懒慵懒懒懒_________________\\n\\n_________________\\n\\n懒懒懒懒_________________\\n\\n_________________\\n\\n_________________\\n\\n慵懒 SchneiderUND da_________________\\n\\n尴尬懒_________________\\n\\n_________________\\n\\n懒尴尬 Intersection_________________\\n\\n_________________\\n\\n_________________\\n\\n懒懒_________________\\n\\n_________________\\n\\n懒懒懒懒懒 Schneider懒_________________\\n\\n懒动摇懒懒懒善意_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n懒懒_________________\\n\\n懒_________________\\n\\n_________________\\n\\n Schneider懒懒orio Schneider懒懒懒懒orio_________________\\n\\n Mär懒_________________\\n\\norio懒_________________\\n\\n大洋_________________\\n\\n懒_________________\\n\\n_________________\\n\\n stere:a m to懒懒au class的 a a懒慵懒懒_________________\\n\\n Intersection懒_________________\\n\\nau di b的outh:aa,a aaの_________________\\n\\n懒懒懒_________________\\n\\n_________________\\n\\n懒 Intersection懒odega懒懒懒_________________\\n\\n善意erezaaa a a aa aa, aaires懒ropol懒_________________\\n\\n懒懒懒odega_________________\\n\\n懒懒 hypoth_________________\\n\\n automate_________________\\n\\naua_fa懒_________________\\n\\n_________________\\n\\n_________________\\n\\n Intersection懒odega_________________\\n\\n_________________\\n\\n堕懒慵 Intersection Schneider懒懒_________________\\n\\n Cair懒 Schneider懒 hypoth_________________\\n\\n懒 Schneider_________________\\n\\n善意懒慵_________________\\n\\n懒_________________\\n\\n_________________\\n\\n_________________\\n\\n懒_________________\\n\\n Cair懒懒 Cairalien Schneider dlaواء Schneider懒_________________\\n\\n懒懒懒懒尴尬懒懒懒_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\n_________________\\n\\nrop懒懒懒_________________\\n\\n懒_________________\\n\\n懒懒_________________\\n\\n懒 Schneider disp的 a:a的 aerrya is的 a的a,的 a:a的 a, f for aaartz懒 Mär_________________\\n\\n_________________\\n\\n懒_________________\\n\\n慵_________________\\n\\n_________________\\n\\n懒懒懒懒alien_________________\\n\\n_________________\\n\\n懒懒懒懒au act de a,的ouve Schneider_________________\\n\\n'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 190,\n",
       "  'completion_tokens': 322,\n",
       "  'total_tokens': 512}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.create_chat_completion(\n",
    "\tmessages = \"vneid_md/huong-dan-su-dung-vneid.pdf-8-0.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
